{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import youtube_dl\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import webvtt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "#os.chdir(\"/Users/shradhitsubudhi/Documents/youtube/downloads\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, static_url_path=\"\")\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Return the main page.\"\"\"\n",
    "    return render_template('theme.html')\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return '<h1> Youtube Sentimental Analysis!</h1>'\\\n",
    "\n",
    "@app.route(\"/form_data\", methods=[\"GET\", \"POST\"])\n",
    "def form_data():\n",
    "\n",
    "    if request.method ==\"POST\":\n",
    "        link = request.form.get('link')\n",
    "\n",
    "    scraping(link)\n",
    "\n",
    "    return link\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_download(link):\n",
    "    \n",
    "    source = os.getcwd()\n",
    "    dest = os.getcwd() + '/down/'\n",
    "    \n",
    "    ydl_opts = {'writesubtitles': True,\n",
    "                'writeautomaticsub': True,\n",
    "                'writeinfojson': True,\n",
    "                'format': 'bestaudio/best',\n",
    "                'keepvideo': False,\n",
    "                'postprocessors': [{'key': 'FFmpegExtractAudio',\n",
    "                                    'preferredcodec': 'wav',\n",
    "                                    'preferredquality': '192'}],\n",
    "                'postprocessor_args': ['-ar', '16000']}\n",
    "\n",
    "\n",
    "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "        meta = ydl.extract_info(link, download=True)\n",
    "\n",
    "    \n",
    "    keys = ['uploader','uploader_url','upload_date','creator','title','description','categories',\n",
    "            'duration','view_count', 'like_count', 'dislike_count','average_rating','start_time', 'end_time',\n",
    "            'release_date', 'release_year']\n",
    "\n",
    "    filtered_d = dict((k, meta[k]) for k in keys if k in meta)\n",
    "    df = pd.DataFrame.from_dict(filtered_d, orient='index').T\n",
    "    df.index = df['title'] \n",
    "    files = os.listdir(source)\n",
    "\n",
    "    for f in files: \n",
    "        if (f.startswith(str(meta['title']))):\n",
    "            shutil.move(f, dest)\n",
    "            #print('done')\n",
    "        else: \n",
    "            #print(str(df['title']))\n",
    "            continue\n",
    "\n",
    "    \n",
    "    sub_titles = glob.glob('./down/*.en.vtt')\n",
    "    \n",
    "    if len(sub_titles) != 0:\n",
    "        vtt = webvtt.read(sub_titles[0])\n",
    "\n",
    "        start_list = list()\n",
    "        end_list = list()\n",
    "        # Storing all the lines as part of the lines list\n",
    "        lines = []\n",
    "\n",
    "\n",
    "        for x in range(len(vtt)):\n",
    "            start_list.append(vtt[x].start)\n",
    "            end_list.append(vtt[x].end)\n",
    "\n",
    "\n",
    "        for line in vtt:\n",
    "            lines.append(line.text.strip().splitlines())\n",
    "\n",
    "            lines = [' '.join(item) for item in lines]\n",
    "            \n",
    "        final_df = pd.DataFrame({'Start_time': start_list, 'End_time': end_list, 'Statement': lines})\n",
    "\n",
    "        sid_obj = SentimentIntensityAnalyzer()\n",
    "        sentiment_scores_vader = [sid_obj.polarity_scores(article) for article in final_df.Statement]\n",
    "\n",
    "        sentiment_category_positive = []\n",
    "        sentiment_category_neutral = []\n",
    "        sentiment_category_negative = []\n",
    "        sentiment_category_compound = []\n",
    "\n",
    "        for sentiments in sentiment_scores_vader:\n",
    "            sentiment_category_positive.append(sentiments['pos'])\n",
    "            sentiment_category_neutral.append(sentiments['neu'])\n",
    "            sentiment_category_negative.append(sentiments['neg'])\n",
    "            sentiment_category_compound.append(sentiments['compound'])\n",
    "        \n",
    "        sentiment_df = pd.DataFrame([[article for article in final_df.Statement],\n",
    "                                         sentiment_category_positive,\n",
    "                                         sentiment_category_neutral,\n",
    "                                         sentiment_category_negative,\n",
    "                                         sentiment_category_compound]).T\n",
    "        sentiment_df['Start_time'] = start_list\n",
    "        sentiment_df['End_time'] = end_list\n",
    "        sentiment_df.columns = ['Statement', 'positive_polarity', 'neutral_polarity', 'negative_polarity',\n",
    "                                    'overall_polarity', 'Start_time', 'End_time']\n",
    "        abcd = sentiment_df.to_json()\n",
    "        \n",
    "        return abcd\n",
    "    return '''<form method =\"POST\">\n",
    "                Enter the Youtube link <input type =\"text\" name =\"link\">\n",
    "                <input type =\"submit\">\n",
    "                </form>'''\n",
    "\n",
    "#app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] LdfSJabF2NI: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: video doesn't have subtitles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] LdfSJabF2NI: Looking for automatic captions\n",
      "[info] Writing video subtitles to: China censors research on CCP virus origin; Wuhan volunteer threatened after speaking about outbreak-LdfSJabF2NI.en.vtt\n",
      "[info] Writing video description metadata as JSON to: China censors research on CCP virus origin; Wuhan volunteer threatened after speaking about outbreak-LdfSJabF2NI.info.json\n",
      "[download] Destination: China censors research on CCP virus origin; Wuhan volunteer threatened after speaking about outbreak-LdfSJabF2NI.webm\n",
      "[download] 100% of 20.85MiB in 00:0272MiB/s ETA 00:00known ETA\n",
      "[ffmpeg] Destination: China censors research on CCP virus origin; Wuhan volunteer threatened after speaking about outbreak-LdfSJabF2NI.wav\n",
      "Deleting original file China censors research on CCP virus origin; Wuhan volunteer threatened after speaking about outbreak-LdfSJabF2NI.webm (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "link =  \"https://www.youtube.com/watch?v=LdfSJabF2NI\"\n",
    "scraping_download(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webvtt\n",
    "\n",
    "vtt = webvtt.read(\"down/zbjmnwfc.en.vtt\")\n",
    "start_list = list()\n",
    "end_list = list()\n",
    "# Storing all the lines as part of the lines list\n",
    "lines = []\n",
    "\n",
    "\n",
    "for x in range(len(vtt)):\n",
    "    start_list.append(vtt[x].start)\n",
    "    end_list.append(vtt[x].end)\n",
    "\n",
    "\n",
    "for line in vtt:\n",
    "    lines.append(line.text.strip().splitlines())\n",
    "\n",
    "    lines = [' '.join(item) for item in lines]\n",
    "\n",
    "final_df = pd.DataFrame({'Start_time': start_list, 'End_time': end_list, 'Statement': lines})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f.endswith('.wav')#('We explain the COVID curve, herd immunity, R-naught & pool-testing-4zF7IQ_xqTQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files: \n",
    "    if (f.startswith('We explain the COVID curve, herd immunity, R-naught & pool')):\n",
    "        shutil.move(f, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic caption is not be created by YouTube.\n"
     ]
    }
   ],
   "source": [
    "sub_titles = glob.glob('./*.en.vtt')\n",
    "\n",
    "if len(sub_titles) != 0:\n",
    "    print(f)\n",
    "else:    \n",
    "    print('Automatic caption is not be created by YouTube.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files.starts_with(\"We explain the COVID curve, herd immunity, R-naught & pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We explain the COVID curve, herd immunity, R-naught & pool-testing-4zF7IQ_xqTQ.info.json',\n",
       " 'We explain the COVID curve, herd immunity, R-naught & pool-testing-4zF7IQ_xqTQ.wav']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "source = os.getcwd()\n",
    "dest = os.getcwd() + '/down/'\n",
    "files = os.listdir(source)\n",
    "\n",
    "for f in files: \n",
    "    if (f.startswith('We explain the COVID curve, herd immunity, R-naught & pool')): # change it to appropriate\n",
    "        print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"./down/You're wrong about more than you think.-ioxWuCd-mn0.en.vtt\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sub_titles = glob.glob('./down/*.en.vtt')\n",
    "#sub_titles = \n",
    "glob.glob('./down/*.en.vtt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
